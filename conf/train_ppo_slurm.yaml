defaults:
  - train_ppo
  - slurm
  - _self_

batch_T: 256
batch_B: 8
use_slurm: True
